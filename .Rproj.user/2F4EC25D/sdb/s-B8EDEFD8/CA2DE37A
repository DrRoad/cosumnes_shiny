{
    "collab_server" : "",
    "contents" : "# Cosumnes River Groundwater Observatory  \n\n**Log of Research activities**  \n\n***\n\nFebruary 21, 2018  \n\n* performed load tests for the webapp on:  \n    + googlesheets : failed  \n    + github : passed\n\npros of using github: no need to set up remote DB  \ncons of using github: the webapp is as real-time as the user who downloads, cleans, and uploads data from SQLite  \n\n\n* successfully queried the SQlite database on Amy's computer using `RSQlite`.  \n* the body of each email needs to cleaned for the appropriate data  \n* determined that [AWS RDS](https://aws.amazon.com/rds/) is an option for remote storage  \n* communicated with Mauricio and Solonist people to investigate remote DB options  \n\n***\n\nFebruary 22, 2018  \n\n* confirmed with Mauricio and Solonist that a remote DB is out of the question  \n    + Solonist only offers SQLite, email and text notifications with the hardware we're using (level sender)  \n* investiagted the potential of `gmailr` (access to gmail API) to query email data  \n    + load test: failed  \n        + 200 emails ~= 30 seconds  \n        + 2000 emails ~= 300 seconds (5 minutes)  \n* new plan:  \n    + use either UCD servers or AAWS RDS to store clean data  \n    + write an automated script that queries SQLite database daily, cleans data, and pushes it to the remote DB  \n        + pros: very fast for webapp to access data, because the query is smaller, and we remove the cleaning step  \n        + cons: technical to set up, but I love a new challenge  \n* sent email to Chris to investigate if UCD can give us remote server space, and if not, if he recommends AWS RDS  \n    + he recommends campus resources. mySQL is free  \n    + the R interface to mySQL is well documented  \n        + [slides](https://www.slideshare.net/RsquaredIn/rmysql-tutorial-for-beginners)  \n        + [CRAN](https://cran.r-project.org/web/packages/RMySQL/RMySQL.pdf)  \n* found these resources in setting up an automated task in Windows  \n    + [Stack Overflow question](https://stackoverflow.com/questions/2793389/scheduling-r-script)  \n    + [blog post](https://www.techradar.com/news/software/applications/how-to-automate-tasks-in-windows-1107254)  \n* Talked with Omen (IT) and named project mySQL database \"**gw_observatory**\"  \n    + cost is $0 to set up the database, and $39/hr to pay a developer to build the application.  \n    + Rich will build the application, so the cost will be free.  \n* Database details:  \n    + type: mySQL  \n    + host = sage.metro.ucdavis.edu  \n    + user = gw_observatory  \n    + schema = gw_observatory  \n    + password = not displayed for security purposes  \n\n\nTO DO:  \n\n* Amy:  \n    + change the reporting interval from 6 hour intervals to 24 hour intervals to save battery life  \n    + read up on strings to prepare for cleaning SQLite data  \n* Rich:  \n    + set up the remote DB  \n    + perform load tests on Shiny App -  aim to account for 10 years of hourly data.  \n\n***\n\nFebruary 23, 2018  \n\n* Asked System Admin to add shinyapps.io IP addresses to mySQL databse whitelist.  \n    + [RStudio Support](https://support.rstudio.com/hc/en-us/articles/217592507-How-do-I-give-my-application-on-shinyapps-io-access-to-my-remote-database-#)  \n    + [Pool documentation](https://cran.r-project.org/web/packages/pool/pool.pdf)  \n    + [Databases in R](http://db.rstudio.com/pool/)  \n\n    \n\n***\n\nFebruary 26, 2018  \n\n* was blocked from accessing mySQL server, so asked Omen to whitelist my IP and Amy's IP  \n* wrote some dummy data to the mySQL server large enough for a load test (about 2 years of data for 13 wells)  \n* created a minimal ShinyApp to query and load test the mySQL database  \n    + query: works well  \n    + load test: works well--size of data is not a problem  \n* uploaded to shinyapps.io, and get the following error:  \n    + `An error has occurred. Unable to connect to worker after 60.00 seconds; startup took too long.`  \n\n\n***\n\nFebruary 27, 2018  \n\n* Troubleshooting--it works locally, but not online because:  \n    + data is too big, or memory needed > 1GB, and I need to upgrade to a Shiny Apps plan  \n        + test with small data (USArrests) -- same error as before.  \n        + not size or memory limited  \n    + [try using ROCBC package](http://docs.rstudio.com/shinyapps.io/applications.html#config-package)  \n        + not relevant  \n    + check out the `config` package  \n        + not relevant  \n    + try `pool` package  \n        + same error  \n    + shinyapps.io IP addresses are not whitelited  \n        + confirm they are whitelisted with Omen  \n    + Stack Overflow  \n        + posted  \n    + shiny apps google group  \n        + posted  \n    \n    \n***\n\nFebruary 28, 2018  \n\n* Successfully deployed app on shinyapps.io and resolved connection issue with campus MySQL server  \n    + issue was that we needed to create a port to the database--metro has a burly firewall  \n\n***\n\nMarch 6, 2018  \n\n* code to clean SQLite data and organize it into a table  \n* the data is pretty messy at this point, because the sampling and reporting interval have changed so much during setup, and this changes the output of each reporting email\n* In order to clean this data most effectively, set the reporting rate to 24 hours, the sample rate to 1 hour, and collect new data, so that the solution built doesn't have to account for emails of different size. \n\n\n***\n\nMarch 7, 2018  \n\n* features to build:  \n    + shiny dashboard structure  \n    + download data  \n    + plotly hydrograph of daily averages  \n    + map to click on  \n* spent time looking at CCLite4 apps and reading code  \n* brainstorming of app features  \n* try to find workaround without rCharts  \n* implemented well locations into cclite4 app  \n\n***\n    \nMarch 8, 2018  \n\n* performed load test on highcharts and plotly for group plot.  \n    + Plotly much faster, easily scalable to daily measurements at 15 wells over 5 years in ~20 seconds  \n    + plotly doesn't requre xts data types, as highchart does  \n* built lots of features  \n    + leaflet  \n    + individual hydrograph for a selected well  \n        + connection between selected well, drop down menu, and hydrograph  \n    + network plot with geom_smooth average line  \n    + logo and theme  \n* still needs:  \n    + about_the_site .md with a nice AI figure    \n    + about floodplain recharge .md with figures  \n    + about page:\n\n\n***\n\nMarch 9, 2018  \n\n* implemented a download button  \n* tested putting in a data table, and removed it  \n* blocked by  \n    + example of some 24 hour data to clean  \n    + actual data stream coming in that I can push to UCD MySQL server  \n\n\n\n***\n\nMarch 14, 2018  \n\n* still blocked by 24 hour data  \n* learned that data won't come in regualrly, and I'll have to deal with missing data, as well as backing the data up  \n\n**NEW PLAN**  \n\n* write a script that:  \n    + first queries the cloud db for missing values and updates them if new values are in the system  \n    + checks the date on the computer, looks for the date closest to that in the sqlite database, cleans that data, and appends that data to the overall dataframe in the cloud server  \n    + Missing data are stored as NA  \n    + appends new data to the table  \n    + [updates the table](https://www.w3schools.com/sql/sql_update.asp) with previously missing values  \n\n\n***\n\nMarch 15, 2018  \n\n* moved sqlite files and levelsender from Amy's computer to mine  \n* tail of data that came in was at:  \n\n           ReceivedDate  \n161 2018-03-14 17:12:16  \n162 2018-03-14 14:37:42  \n163 2018-03-14 13:45:14  \n164 2018-03-14 13:01:03  \n165 2018-03-15 13:01:03  \n166 2018-03-15 14:38:56  \n\n* check tomorrow that this new data is coming in  \n* start with data that comes at 24 hour intervals: begins 3/15? Ask Amy.  \n\n***\n\nMarch 16, 2018 \n\n\n\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    ",
    "created" : 1521154027969.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2621966124",
    "id" : "CA2DE37A",
    "lastKnownWriteTime" : 1521157835,
    "last_content_update" : 1521157835631,
    "path" : "~/GitHub/cosumnes_shiny/README.Rmd",
    "project_path" : "README.Rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}